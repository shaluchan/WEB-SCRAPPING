{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18eba88d-d4a9-40f2-bf62-1ec0de64ebbd",
   "metadata": {},
   "source": [
    "scrappigng job data from scrapped links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1b558-27f0-40ac-80a1-82a2dca1ef9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from: https://angel.co/company/abstract/jobs\n",
      "Failed to fetch job link: https://angel.co/company/abstract/jobs\n",
      "Error: 403 Client Error: Forbidden for url: https://wellfound.com/company/abstract/jobs\n",
      "Site Name: N/A\n",
      "Fetching data from: https://jobs.amadeus.com/\n",
      "Site Name: Pardon Our Interruption\n",
      "Fetching data from: https://www.amazon.jobs/en/\n",
      "Site Name: Amazon.jobs: Help us build Earthâ€™s most customer-centric company.\n",
      "Fetching data from: https://www.instahyre.com/jobs-at-apna/\n",
      "Site Name: apna Careers | Jobs at apna - Instahyre\n",
      "Fetching data from: https://appen.com/jobs/\n",
      "Site Name: Earn & Learn Remotely - Appen Crowd\n",
      "Fetching data from: https://jobs.aptiv.com/\n",
      "Failed to fetch job link: https://jobs.aptiv.com/\n",
      "Error: HTTPSConnectionPool(host='jobs.aptiv.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x78822816fad0>, 'Connection to jobs.aptiv.com timed out. (connect timeout=None)'))\n",
      "Site Name: N/A\n",
      "Fetching data from: https://www.linkedin.com/company/aryaka-networks/jobs?originalSubdomain=in\n",
      "Failed to fetch job link: https://www.linkedin.com/company/aryaka-networks/jobs?originalSubdomain=in\n",
      "Error: 403 Client Error: Forbidden for url: https://www.linkedin.com/company/aryaka-networks/jobs?originalSubdomain=in\n",
      "Site Name: N/A\n",
      "Fetching data from: https://jobs.adp.com/\n",
      "Site Name: Jobs & Careers at ADP\n",
      "Fetching data from: https://www.avalara.com/us/en/about/jobs/job-openings.html\n",
      "Site Name: Avalara North America\n",
      "Fetching data from: https://benchmarkit.zohorecruit.com/jobs/Careers\n",
      "Site Name: Jobs at Careers\n",
      "Fetching data from: https://www.linkedin.com/company/billdesk/jobs/\n",
      "Failed to fetch job link: https://www.linkedin.com/company/billdesk/jobs/\n",
      "Error: 403 Client Error: Forbidden for url: https://www.linkedin.com/company/billdesk/jobs/\n",
      "Site Name: N/A\n",
      "Fetching data from: https://www.bitdefender.com/company/job-opportunities/\n",
      "Site Name: Bitdefender Job Opportunities - Join the Bitdefender Team!\n",
      "Fetching data from: https://bb.wd3.myworkdayjobs.com/BlackBerry/jobs\n",
      "Site Name: Workday is currently unavailable.\n",
      "Fetching data from: https://careers.bloomberg.com/job/search\n",
      "Site Name: Job Search | Bloomberg Careers\n",
      "Fetching data from: https://jobs.bnymellon.com/\n",
      "Site Name: Careers at BNY Mellon\n",
      "Fetching data from: https://jobs.boeing.com/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Function to filter links containing the word \"job\"\n",
    "def filter_job_links(links):\n",
    "    job_links = []\n",
    "    for link in links:\n",
    "        if 'job' in link.lower():\n",
    "            job_links.append(link)\n",
    "    return job_links\n",
    "\n",
    "# Function to fetch site name and other details from the job link\n",
    "def fetch_site_details(job_link):\n",
    "    site_details = {}\n",
    "\n",
    "    try:\n",
    "        # Define headers to mimic a real browser request\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "\n",
    "        # Send a GET request to the job link with headers\n",
    "        response = requests.get(job_link, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for any HTTP error\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Failed to fetch job link:\", job_link)\n",
    "        print(\"Error:\", e)\n",
    "        return {}\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Example: Extract site name\n",
    "        site_name_element = soup.find('title')\n",
    "        site_name = site_name_element.text.strip() if site_name_element else \"N/A\"\n",
    "\n",
    "        # Example: Extract other details\n",
    "        # You can add more extraction logic here as needed\n",
    "        \n",
    "        # Store the extracted site details in a dictionary\n",
    "        site_details = {\n",
    "            'Site Name': site_name,\n",
    "            # Add more details here as needed\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to fetch job link:\", job_link)\n",
    "\n",
    "    return site_details\n",
    "\n",
    "# Open the text file for reading\n",
    "with open('links.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "\n",
    "    # Use regular expression to find links in the file contents\n",
    "    links = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', file_contents)\n",
    "\n",
    "    # Filter links containing the word \"job\"\n",
    "    job_links = filter_job_links(links)\n",
    "\n",
    "    # Print the filtered job links\n",
    "    for job_link in job_links:\n",
    "        print(\"Fetching data from:\", job_link)\n",
    "\n",
    "        # Fetch site details from the job link\n",
    "        site_details = fetch_site_details(job_link)\n",
    "\n",
    "        # Print the extracted site details\n",
    "        print(\"Site Name:\", site_details.get('Site Name', 'N/A'))\n",
    "        # Print more site details as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926811e0-968a-4c84-8e8c-16f264b9feba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
